# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18rTplUZYzAc8yJao8CeAmr3gq8McS-zp
"""

import numpy as np

# Define constraints
skin_tones = [ 'black', 'dark brown' , 'brown' , 'olive' , 'white']
colors = ['bright white',  'ruby red',  'bright purple',  'cobalt blue',  'royal blue',  'tomato red',  'denim blue',
          'citrine',  'olive green',  'peach', 'copper', 'russet', 'pumpkin orange', 'taupe', 'silver', 'plum', 'maroon', 'forest green',
          'black', 'mauve', 'pastel lilac', 'amber', 'emerald green', 'burnt orange', 'carmine', 'bordeaux', 'burgundy', 'fuchsia',
          'blush pink', 'sapphire blue', 'coral', 'jade', 'black', 'charcoal', 'mahogany', 'royal blue', 'emerald green', 'silver',
          'forest green', 'champagne', 'seafoam green', 'black', 'periwinkle', 'olive green', 'peach', 'teal', 'rose', 'soft pink', 'crimson',
          'light grey']
learning_rate = 0.1
discount_factor = 0.9
exploration_rate = 1.0
min_exploration_rate = 0.01
exploration_decay = 0.01

# Survey data (Example: Ratings 1-5 for each color per skin tone)
survey_ratings = {
    'brown': [3,	5,	5,	2,	4,	1,	4,	4,	4,	5,
              4,	2,	3,	2,	3,	3,	2,	2,	2,	3,
              4,	5,	3,	2,	2,	2,	3,	3,	4,	3,
              5,	4,	5,	3,	3,	5,	5,	4,	5,	5,
              3,	3,	4,	4,	3,	4,	5,	5,	1,	5,
              3,	4,	5,	3,	4,	4,	1,	5,	3,	3,
              2,	2,	5,	4,	5,	4,	5,	2,	3,	3,
              1,	4,	5,	2,	3,	2,	4,	3,	2,	3,
              4,	3,	2,	5,	3,	4,	3,	5,	1,	3,
              2,	5,	5,	3,	3,	1,	1,	3,	5,	2,
              2,	3,	2,	3,	2,	3,	4,	4,	2,	4,
              5,	3,	3,	2,	5,	4,	4,	5,	4,	3,
              3,	4,	3,	3,	5,	5,	5,	3,	5,	3,
              5,	5,	5,	4,	4,	5,	3,	4,	3,	3,
              5,	2,	3,	4,	5,	2,	3,	3,	4,	4,
              3,	4,	4,	3,	5,	3,	4 ],
    'dark brown': [5,	5,	5,	4,	5,	2,	4,	3,	4,	5,
                   5, 3,	1,	4,	5,	3,	2,	3,	1,	3,
                   3,	4,  3,	4,	5,	4,	5,	5,	5,	5,
                   5,	3,	4,  5,	5,	5,	5,	4,	5,	5,
                   5,	3,	3,	3,  2,	2,	3,	3,	5,	2,
                   2,	5,	5,	5,	5,  3,	3,	4,	3,	3,
                   4,	1,	4,	3,	4,	2,  2,	2,	4,	3,
                   4,	2,	3,	4,	2,	3,	3,  1,	5,	3,
                   3,	1,	3,	2,	4,	3,	2,	2,  3,	1,
                   4,	5,	4,	4,	5,	3,	3,	3,	2,  3,
                   3,	2,	2,	4,	3,	2,	1,	5,	5,	3,
                   4,	2,	5,	2,	3,	4,	1,	2,	3,	4,
                   5, 5,	3,	3,	4,	2,	2,	4,	4,	5,
                   3,	3,  3,	4,	4,	3,	5,	4,	4,	4,
                   3,	4,	4,  3,	4,	2,	5,	3,	3,	5,
                   4,	5,	5,	3,  2,	1],
    'olive': [4,	5,	4,	3,	2,	1,	4,	3,	5,	5,
              4,	3,	2,	2,	3,	3,	4,	4,	4,	5,
              3,	4,	4,	4,	5,	4,	5,	4,	4,	4,
              5,	5,	3,	5,	5,	5,	3,	2,	2,	3,
              4,	5,	4,	5,	5,	4,	3,	4,	5,	5,
              4,	5,	4,	5,	5,	2,	5,	5,	5,	5,
              5,	3,	5,	1,	3,	2,	4,	4,	4,	2,
              4,	5,	4,	3,	5,	5,	3,	3,	5,	2,
              3,	5,	5,	5,	3,	4,	4,	5,	3,	5,
              4,	4,	2,	3,	5,	4,	3,	2,	4,	5,
              2,	4,	4,	4,	3,	1,	5,	5,	4,	4,
              3,	1,	4,	5,	4,	5,	3,	5,	1,	5,
              5,	2,	5,	2,	1,	3,	5,	4,	4,	5,
              5,	5,	3,	3,	4,	3,	4,	4,	4,	5,
              5,	3,	5,	2,	4,	4,	4,	4,	5,	2,
              5,	3 ],
    'black': [3,	5,	4,	3,	5,	5,	4,	2,	3,	5,
              5,	3,	5,	2,	5,	3,  4,	3,	2,	3,
              1,	2,	3,	2,	1,	1,	3,	2,	3,	1,
              3,	2,  2,	5,	5,	5,	5,	5,	4,	5,
              5,	4,	3,	4,	5,	4,	3,	2,  3,	3,
              1,	2,	3,	3,	3,	2,	5,	5,	2,	3,
              3,	2,	5,	4,  1,	3,	3,	3,	2,	2,
              2,	1,	1,	3,	5,	5,	3,	3,	3,	3,
              2,	2,	4,	5,	3,	4,	3,	1,	3,	2,
              2,	1,	5,	2,	5,	3,  2,	4,	3,	2,
              3,	4,	2,	2,	3,	3,	5,	4,	3,	2,
              4,	2,  3,	3,	5,	3,	4,	4,	3,	5,
              1,	1,	3,	2,	3,	1,	3,	5,  5,	5,
              4,	5,	5,	5,	4,	1,	4,	1,	5,	5,
              2,	5,	5,	1,  2,	2,	3,	4,	4,	1,
              3,	2,	5,	5,	4,	4	],
    'white': [5,	5,	3,	5,	3,	5,	4,	4,	5,	5,
              4,	3,	3,	4,	4,	2,	4,	5,	5,	4,
              2,	4,	5,	5,	4,	5,	5,	4,	4,	5,
              5,	5,	5,	4,	4,	5,	3,	3,	4,	4,
              4,	4,	4,	5,	4,	5,	4,	5,	5,	5,
              5,	2,	5,	5,	5,	5,	4,	5,	5,	5,
              5,	2,	4,	5,	5,	3,	2,	1,	5,	5,
              5,	5,	4,	5,	5,	4,	5,	1,	5,	3,
              4,	5,	4,	5,	5,	4,	5,	5,	5,	5,
              4,	4,	4,	1,	5,	5,	4,	5,	5,	5,
              3,	1,	5,	5,	5,	5,	4,	3,	3,	5,
              5,	5,	4,	5,	4,	5,	3,	5,	3,	4,
              5,	3,	5,	5,	4,	5,	3,	2,	4,	5,
              4,	5,	2,	5,	4,	5,	5,	4,	5,	5,
              5,	5,	5,	4,	5,	1,	4,	5,	4,	4,
              5,	3,	3,	3,	4,	1 ]
}

# Convert ratings to rewards (1-5 rating scale to -2 to +2)
def normalize_rating(rating):
    return rating - 3  # Convert 1-5 ratings to -2 to +2

# Initialize Q-table with zeros
q_table = np.zeros((len(skin_tones), len(colors)))

# Pre-train Q-table using survey data
for skin_tone_index, skin_tone in enumerate(skin_tones):
    # Ensure color_index is within the bounds of colors list
    for color_index, rating in enumerate(survey_ratings[skin_tone][:len(colors)]):
        reward = normalize_rating(rating)
        q_value = q_table[skin_tone_index, color_index]

        # Update Q-table based on survey data (initial pre-training)
        q_table[skin_tone_index, color_index] = q_value + learning_rate * reward

print("Q-table after pre-training with survey data:")
print(q_table)

def recommend_color(skin_tone_index, feedback_rating=None):
    global exploration_rate

    # Choose action (color) based on exploration vs. exploitation
    if random.uniform(0, 1) < exploration_rate:
        action = random.randint(0, len(colors) - 1)
    else:
        action = np.argmax(q_table[skin_tone_index])

    # Update Q-table with live feedback if available
    if feedback_rating is not None:
        reward = get_reward(feedback_rating)
        q_value = q_table[skin_tone_index, action]
        best_future_q = np.max(q_table[skin_tone_index])

        # Q-learning update formula
        q_table[skin_tone_index, action] = q_value + learning_rate * (reward + discount_factor * best_future_q - q_value)

        # Decay exploration rate
        exploration_rate = max(min_exploration_rate, exploration_rate * (1 - exploration_decay))

    return colors[action]